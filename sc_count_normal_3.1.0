#!/bin/env python3

import json
import glob
from subprocess import call

import argparse

DEBUG = None

def get_sample_names_from(simple_csv_filename):
    samples = []
    with open(simple_csv_filename) as fh:
        data_started = False
        for line in fh:
            if data_started:
                fields = line.split(',')
                samples.append(fields[1])
            if line.startswith('Lane'):
                data_started = True
    return samples

def main(args):
    config = args.config

    DEBUG = args.debug

    with open(config) as json_data:
        datasets = json.load(json_data)
        if DEBUG:
            print(datasets)

        for dataset in datasets:
            if DEBUG:
                print("data set: " + dataset)

            transcriptome_path = datasets[dataset]["reference"]

            if DEBUG:
                print("transcriptome_path: " + transcriptome_path)

            fastq_dirs = []

            for run_folder in datasets[dataset]["run_folders"]:
                flowcell = datasets[dataset]["run_folders"][run_folder]
                fastq_path =  run_folder + '/' + flowcell + '/outs/fastq_path'
                fastq_dirs.append(fastq_path)

            fastqs_string = ','.join(fastq_dirs)
            if DEBUG:
                print(fastqs_string)

            samples = datasets[dataset]["samples"]
            if DEBUG:
                print(samples)

            for sample in samples:
                    script_text = """#!/bin/bash
#SBATCH --partition=BioCompute,Lewis,hpc5
#SBATCH --account=warrenlab
#SBATCH --time=2-00:00:00
#SBATCH -J cellranger_count_{sample}
#SBATCH -o cellranger_count_{sample}_%j_o.txt
#SBATCH --cpus-per-task {cores}
#SBATCH --mem {mem}G
module load biocompute/biocompute-modules
module load bcl2fastq/bcl2fastq-2.20.0.422
module load cellranger/cellranger-3.1.0
source /cluster/biocompute/software/cellranger/cellranger-3.1.0/sourceme.bash

cellranger count \
    --id sample_{sample} \
    --transcriptome {transcriptome_path} \
    --fastqs {fastqs_string} \
    --sample {sample} \
    --jobmode local \
    --localcores $SLURM_CPUS_PER_TASK \
    --localmem {mem}
""".format(sample=sample,fastqs_string=fastqs_string,transcriptome_path=transcriptome_path,mem=args.mem,cores=args.cores)

                    script_path = 'dataset_' + dataset + '__sample' + sample + '.sbatch'
                    with open(script_path, 'w') as fh:
                        fh.write(script_text)
    
                    if DEBUG:
                        print(['sbatch',script_path])
                    else:
                        call(['sbatch',script_path])


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
                description='Create FASTQ files for sets of 10X single-cell Illumina data (more functionality forthcoming)'
             )
    parser.add_argument(
        'config',
        type=str,
        help='Name of JSON config file containing a dictionary of sets of lists of run folders to process',
    )
    parser.add_argument(
        '--debug',
        dest='debug',
        action='store_true',
        default=False,
    )
    parser.add_argument(
        '--cores',
        type=str,
        default='24',
        help='Number of cores(threads) to use to process data',
    )
    parser.add_argument(
        '--mem',
        type=str,
        default='120',
        help='GB of memory to use to process data',
    )

    args = parser.parse_args()

    main(args)
